{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/home/tzhao713/Developers/pldi20/benchmark/gpu/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.python.client import session\n",
    "from tensorflow.python.framework import importer\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.summary import summary\n",
    "\n",
    "try:\n",
    "  from tensorflow.contrib.tensorrt.ops.gen_trt_engine_op import *\n",
    "except ImportError:\n",
    "  pass\n",
    "\n",
    "cwd = os.getcwd() + '/'\n",
    "model_path = cwd + 'squeezenet_tflite_pretrained/squeezenet.tflite'\n",
    "model_dir = 'squeezenet_tflite_pretrained/squeezenet.pb'\n",
    "log_dir = './logs/'\n",
    "H = 224\n",
    "W = 224\n",
    "C = 3\n",
    "input_name = 'Placeholder'\n",
    "\n",
    "batch_size = 1\n",
    "n_experiments = 10\n",
    "use_gpu = False\n",
    "filename_suffix = '_raw_graph_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "'''\n",
    "Modify the graph. It is important to disable eager execution since it adds concurrency into profiling...\n",
    "'''\n",
    "\n",
    "\n",
    "gpu_profiling_model_name = 'gpu_profiling_squeezenet.pb'\n",
    "\n",
    "def save_graph(sess, log_dir):\n",
    "    pb_visual_writer = summary.FileWriter(log_dir)\n",
    "    pb_visual_writer.add_graph(sess.graph)\n",
    "\n",
    "## Load a graph, cut off the placeholder, and replace it with a tf.constant.\n",
    "#   This approach ensures that the input data is allocated at the GPU side.\n",
    "with session.Session(graph=ops.Graph()) as sess:\n",
    "    with gfile.GFile(model_dir, 'rb') as f:\n",
    "        graph_def = graph_pb2.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        importer.import_graph_def(graph_def)\n",
    "        \n",
    "        tf_const_input = tf.constant(np.random.rand(batch_size, H, W, C), name='const_input', dtype=tf.float32)\n",
    "        new_graph_def = graph_pb2.GraphDef()\n",
    "        node_buf = None\n",
    "        for node in graph_def.node:\n",
    "            if 'Placeholder' in node.name:\n",
    "                new_graph_def.node.extend([tf_const_input.op.node_def])\n",
    "            else:\n",
    "                if 'conv1/Conv2D' == node.name:\n",
    "                    input_names = node.input\n",
    "                    for (i, n) in enumerate(input_names):\n",
    "                        if n == 'Placeholder':\n",
    "                            node.input[i] = tf_const_input.name\n",
    "                new_graph_def.node.extend([copy.deepcopy(node)])\n",
    "       \n",
    "        with gfile.GFile(gpu_profiling_model_name, 'wb') as fn:\n",
    "            serialized_str = new_graph_def.SerializeToString()\n",
    "            fn.write(new_graph_def.SerializeToString())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "'''\n",
    "Profile scopes\n",
    "'''\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "cpu_tline = 'cpu_time_line.json'\n",
    "\n",
    "def save_graph_with_suffix(sess, log_dir, suffix):\n",
    "    pb_visual_writer = summary.FileWriter(log_dir, filename_suffix=suffix)\n",
    "    pb_visual_writer.add_graph(sess.graph)\n",
    "    \n",
    "def test_inference(batch_size, model_dir, timeline_fname, session_conf=None):\n",
    "    with session.Session(graph=ops.Graph(), config=session_conf) as sess:\n",
    "        with gfile.GFile(model_dir, 'rb') as f:\n",
    "            graph_def = graph_pb2.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            importer.import_graph_def(graph_def)\n",
    "            sess.graph.as_default()\n",
    "            \n",
    "            options = tf.compat.v1.RunOptions(trace_level=tf.compat.v1.RunOptions.FULL_TRACE) \n",
    "            run_metadata = tf.compat.v1.RunMetadata()\n",
    "            g = sess.graph\n",
    "            output_tensor = g.get_tensor_by_name(\"import/ArgMax:0\")\n",
    "            try:\n",
    "                input_tensor = g.get_tensor_by_name(\"import/Placeholder:0\")\n",
    "                np_val = np.random.rand(batch_size, H, W, C) \n",
    "                _ = sess.run(\n",
    "                    output_tensor, feed_dict={input_tensor: np_val}, options=options, run_metadata=run_metadata\n",
    "                )\n",
    "            except KeyError:\n",
    "                _ = sess.run(\n",
    "                    output_tensor, feed_dict=dict(), options=options, run_metadata=run_metadata\n",
    "                )\n",
    "            \n",
    "            fetched_timeline = timeline.Timeline(run_metadata.step_stats)\n",
    "            serialized_trace = fetched_timeline.generate_chrome_trace_format()\n",
    "            with open(timeline_fname, 'w') as flog:\n",
    "                flog.write(serialized_trace)\n",
    "                "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%  \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#TODO: It seems that tensorflow const_propped the results since none of the nodes are data dependent...\n",
    "#   As a result the runtime is spent on evaluating a const op...\n",
    "# test_inference(1, gpu_profiling_model_name, './logs/cpu_timeline_no_placeholder.json', session_conf)\n",
    "\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "test_inference(1, model_dir, './logs/cpu_timeline.json', session_conf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}